{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9224e35d",
   "metadata": {},
   "source": [
    "# Reconnaissance d'images avec la Teachable Machine\n",
    "\n",
    "**Objectif:** Découvrir l'apprentissage automatique en entraînant un système de reconnaissance d'images avec l'outil en ligne 'Teachable Machine' de Google. \n",
    "\n",
    "\n",
    "|||\n",
    ":--- | :--- |\n",
    "|Âge |10 à 18 ans|\n",
    "|Notions abordées|Intelligence artificielle, apprentissage automatique, classification d'images, modèle de prédictions.|\n",
    "|Objectifs pédagogiques ([selon MIT IA Ethics, page 7](https://docs.google.com/document/d/1pQ8D4iDnwKoiveJOZZgy6SLvgDD1nYQOPFUwyuBpEic/edit#heading=h.1et5vs39qkyh))|1. Savoir que l'intelligence artificielle est un type d'algorithme spécifique et comporte trois parties spécifiques : ensemble de données, algorithme d'apprentissage et prédiction (1.a.). <br>2. Comprendre le problème de la classification dans le contexte de l'apprentissage automatique supervisé. Comprendre comment la quantité de données d'entraînement affecte la précision et la robustesse d'un modèle d'apprentissage automatique supervisé. (1c)<br> 3. Comprendre l'effet des données d'entraînement sur la précision d'un système d'apprentissage automatique (2.c). <br> 4. Comprendre comment la composition des données d'entraînement affecte “le résultat”  d'un système d'apprentissage automatique supervisé.<br> 5. Identifier les ensembles de données nécessaires pour former un système d'IA pour atteindre cet objectif (4.b).|\n",
    "| Durée| 2 heures|\n",
    "| Dispositif pédagogiques| Par groupe de 2|\n",
    "| Matériel| Un laptop/tablette par groupe de 2, avec connexion à Internet|\n",
    "| Prérequis| Aucun|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece832a0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "La reconnaissance d'images par un ordinateur est une forme d'intelligence artificelle basée sur l'apprentissage automatique: Des exemples d'images de différentes catégories sont montrés à l'ordinateur, et un algorithme d'apprentissage est utilisé pour permettre à l'ordinateur de reconnaître les différentes catégories. \n",
    "\n",
    "Vocabulaire utile:\n",
    "\n",
    "* Les catégories d'images à reconnaître (sourire, grimace, objet, etc ...) sont appelées *classes*\n",
    "* L'ensemble des exemples des différentes classes que l'on utilise pour l'apprentissage s'appelle le *jeu de données d'apprentissage*\n",
    "* L'apprentissage automatique est le terme employé lorsque l'on montre des exemples de ce que l'ordinateur doit apprendre à reconnaître\n",
    "* Le système de reconnaissance est plus couramment appelé *modèle de prédiction*.\n",
    "\n",
    "Dans le cas de la classification d'images, un modèle de prédiction est donc entrainé à reconnaître différentes classes d'images à partir d'un jeu de données d'apprentissage. \n",
    "\n",
    "L'outil que nous utilisons ici pour entraîner le modèle d'apprentissage automatique est la Teachable Machine, qui permet d'entraîner facilement un modèle de reconnaissance d'images en prenant des photos depuis la webcam. Vous associez les images à des classes que le modèle devra reconnaître. La création du modèle (l'entraînement) est fait sur le cloud par un service de Google. \n",
    "\n",
    "Nous donnons comme exemples la reconnaissance d'émotions sur un visage (sourire, grimace, ou neutre) et la détection d'objet sur un sol martien. Le tutoriel peut être adapté librement à d'autres applications de reconnaissance d'images (objet, visage, etc, ...). \n",
    "\n",
    "Nous montrons enfin comment ensuite tester son système (aussi appelé 'modèle') sur de nouvelles images, et exporter le modèle pour pouvoir l'utiliser dans un programme Scratch ou Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e988c",
   "metadata": {},
   "source": [
    "## Teachable machine\n",
    "\n",
    "Allez sur le site de la Teachable Machine à [https://teachablemachine.withgoogle.com](https://teachablemachine.withgoogle.com). La langue française peut être choisie dans la liste déroulante qui se trouve tout en bas de la page, à droite.\n",
    "\n",
    "\n",
    "\n",
    "Cliquez sur \"Commencez\".\n",
    "\n",
    "<img src=\"images/TM_1_commencer.jpg\" width=\"900\"/> \n",
    "\n",
    "Dans la page \"Nouveau projet\", cliquez sur \"Projet image\".\n",
    "\n",
    "\n",
    "<img src=\"images/TM_2_projet_image.jpg\" width=\"900\"/> \n",
    "\n",
    "Puis cliquez sur \"Modèle d'image standard\".\n",
    "\n",
    "<img src=\"images/TM_Image.jpg\" width=\"900\"/> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1b659",
   "metadata": {},
   "source": [
    "## Interface pour entraîner le modèle\n",
    "\n",
    "Après avoir cliqué que \"Modèle d'image standard\", l'interface permettant de faire un entraînement s'affiche:\n",
    "\n",
    "\n",
    "<img src=\"images/TM_3_entrainement_start.jpg\" width=\"900\"/> \n",
    "\n",
    "\n",
    "Elle est composée de trois parties:\n",
    "\n",
    "* A gauche, vous pouvez ajouter des images pour différentes classes. Par défaut, l'interface vous propose d'ajouter des images pour deux classes différentes, qui s'appellent 'Class 1' et 'Class 2'. Vous pouvez ajouter des classes en cliquant sur 'Ajouter une classe' en bas. \n",
    "* Au milieu, le bouton 'Entraînement' vous permet d'entraîner le modèle.\n",
    "* A droite, dans 'Aperçu', vous pourrez tester et exporter le modèle une fois que celui-ci aura été entraîné. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b88571",
   "metadata": {},
   "source": [
    "## Choix des classes\n",
    "\n",
    "Le choix des classes dépend du problème de classification que vous voulez faire. Nous allons ici montrer deux exemples: Un classifieur qui reconnaît vos émotions sur votre visage (souriant, faché, ou neutre), et un classifieur capable de retrouver des tubes sur un sol martien (ce classifieur pourra servir plus tard pour les activités liées à Mars et à la construction d'un rover). \n",
    "\n",
    "Vous pouvez bien sûr entraîner vos classifieur à faire autre chose, comme reconnaître des objets, des fruits, ou votre visage et ceux de vos amis! \n",
    "\n",
    "Pour l'entraînement, il est recommandé de prendre au moins quelques dizaines d'images. Renommez les classes comme vous le souhaitez en cliquant sur l'icône de crayon associé à chaque classe, puis appuyez sur l'icône de caméra pour prendre différentes images de la classe correspondante. \n",
    "\n",
    "Lorsque vous cliquerez sur la caméra, il est possible que le navigateur Web vous demande l'autorisation d'utiliser la caméra. Dans ce cas, autorisez-le.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794faa7a",
   "metadata": {},
   "source": [
    "## Exemple pour un classificateur d'émotions\n",
    "\n",
    "Dans le cas d'un classifieur d'émotions, nous avons pris ici une cinquantaine d'images de trois catégories différentes: Sourire, faché et neutre. Trois exemples de photos de chacune des trois classes sont données ci-dessous.\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> \n",
    "            <img src=\"images/sourire.png\"  width=\"300\"/> \n",
    "        </td>\n",
    "        <td> \n",
    "            <img src=\"images/faché.png\" alt=\"drawing\" width=\"300\"/> \n",
    "        </td>\n",
    "        <td> \n",
    "            <img src=\"images/neutre.png\" width=\"300\"/>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> \n",
    "            <div  align=\"center\">Exemple de classe: Sourire</div>\n",
    "        </td>\n",
    "        <td> \n",
    "             <div  align=\"center\">Exemple de classe: Faché</div>\n",
    "        </td>\n",
    "        <td> \n",
    "             <div  align=\"center\">Exemple de classe: Neutre</div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Une fois que les trois classes sont renommées et que les images ont été prises pour chacune des trois classes, l'interface ressemble à ceci:\n",
    "\n",
    "\n",
    "<img src=\"images/TM_4_Emotion.jpg\" width=\"900\"/> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8c542",
   "metadata": {},
   "source": [
    "### Entraînement et test du modèle\n",
    "\n",
    "Cliquez ensuite sur \"Entraînement\". Cela prend en général moins d'une minute pour que l'entraînement se termine. Une fois celui-ci terminé, la partie de droite 'Aperçu' affichera l'image provenant de la webcam, et vous permettra de tester votre modèle.\n",
    "\n",
    "<img src=\"images/TM_5_emotions.jpg\" width=\"900\"/> \n",
    "\n",
    "\n",
    "Vous pourrez remarquer que le modèle de prédiction fonctionnera moins bien si vous vous approchez ou vous éloignez de la webcam, ou si les conditions d'éclaraige ou l'arrière-plan changent. Afin de rendre votre modèle le plus fiable possible, assurez-vous de prendre des exemples assez variés (en vous approchant ou vous éloignant de la caméra, et en utilisant des arrière-plans différents).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3a0b0",
   "metadata": {},
   "source": [
    "### Exportation du modèle\n",
    "\n",
    "Exportez votre modèle pour pouvoir l'utiliser ensuite avec Adacraft (Scratch) ou Python. Pour cela, cliquez sur 'Exportez'. La fenêtre suivante apparaît:\n",
    "\n",
    "<img src=\"images/TM_6_exporter.jpg\" width=\"600\"/> \n",
    "\n",
    "#### Export du modèle pour une utilisation avec Adacraft (Scratch)\n",
    "\n",
    "Dans l'onglet 'Tensorflow.js', cliquez sur 'Importer le modèle'. Cela prend environ deux minutes. Un lien vers le modèle apparaitra comme ci-dessous:\n",
    "\n",
    "<img src=\"images/TM_7_importer.jpg\" width=\"600\"/> \n",
    "\n",
    "\n",
    "Copier-le pour pouvoir le réutiliser plus tard dans le bloc Modèle d'Adacraft (vous pouvez cliquez sur 'Copier' en bas à droite de la fenêtre pour copier le lien, que vous pourrez ensuite coller dans Adacraft).\n",
    "\n",
    "#### Export du modèle pour une utilisation avec Python\n",
    "\n",
    "Pour l'utilisation du modèle avec Python, il faut utiliser la version Tensorflow Lite du modèle. Pour cela, allez dans l'onglet 'Tensorflow Lite', sélectionner 'Virgule flottante'.\n",
    "\n",
    "\n",
    "<img src=\"images/TM_6_Exporter_Python.jpg\" width=\"600\"/> \n",
    "\n",
    "Cliquez ensuite sur 'Télécharger mon modèle'. Vous devrez attendre environ 30 secondes pour que le modèle soit converti. Une fenêtre apparaîtra ensuite pour vous permettre de télécharger un fichier s'appelant 'converted_tflite.zip', qui fait environ 2 mégaoctets. Téléchargez le ficher en ouvrez l'archive 'zip'. L'archive contient deux fichiers:\n",
    "\n",
    "* Un ficher texte 'labels.txt'\n",
    "* Un ficher 'model_unquant.tflite' qui pourra être ouvert par Python pour utiliser le modèle.\n",
    "\n",
    "Note: Si vous avez un Coral, dans l'onglet 'Tensorflow Lite', sélectionner 'EdgeTPU', puis 'Télécharger mon modèle'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a70d6a",
   "metadata": {},
   "source": [
    "## Reconnaissance de tubes sur un sol martien\n",
    "\n",
    "Le second exemple que nous donnons a pour but de faire un classifieur capable de dire si un tube est présent sur un sol martien. On distingue donc deux classes: Soit l'image perçue par la caméra contient un échantillon (un tube contenant des poussières de sol martien), soit elle n'en contient pas. Nous appellerons la première classe \"Sol\", et la seconde classe \"Tube\".\n",
    "\n",
    "Pour faire l'entraînement, l'image ci-dessous pourra être au préalable imprimée. On y voit un tube posé sur un sol martien (le tube est à peu près au centre). \n",
    "\n",
    "<img src=\"images/sol-martien-avec-tube.jpg\" width=\"900\"/> \n",
    "\n",
    "Les étapes sont ensuite les même que précédemment, pour entraîner, tester et exporter le modèle. \n",
    "\n",
    "Pour l'entraînement, définissez deux classes: 'Sol' et 'Tube'. Ajoutez ensuite des photos avec la webcam de parties\n",
    "de l'image où seul le sol est présent pour la classe sol. Faites de même pour la classe tube, en prenant des photos sur lesquelles le tube est visible. Une fois les photos prises, vous devriez obtenir un jeu de données tel que celui illustré ci-dessous:\n",
    "\n",
    "<img src=\"images/TM_4_tube_sol.jpg\" width=\"900\"/> \n",
    "\n",
    "Lancez ensuite l'entraînement en cliquant sur le bouton 'Entraînement'. Une fois celui-ci terminé (environ une minute), vous pouvez testez votre modèle en déplaçant la feuille devant la webcam. Vérifiez que le modèle reconnaît correctement la présence du tube:\n",
    "\n",
    "<img src=\"images/TM_5_tube_sol.jpg\" width=\"900\"/> \n",
    "\n",
    "Vous pouvez exportez votre modèle pour une utilisation vers Adacrcat (Scratch) ou Python de la même manière que celle décrite ci-dessus pour la reconnaissance d'émotions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90693e",
   "metadata": {},
   "source": [
    "## Résumé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d317c2",
   "metadata": {},
   "source": [
    "## Allez plus loin\n",
    "\n",
    "* Reconnaissance de pose, de sons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666d833",
   "metadata": {},
   "source": [
    "## Références et lien utiles\n",
    "\n",
    "* https://projects.raspberrypi.org/en/projects/image-id-coral/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
